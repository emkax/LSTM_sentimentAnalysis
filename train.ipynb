{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Data Preproccesing"
      ],
      "metadata": {
        "id": "vzi--2mkjf2X"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "E5fX_IVNYAID"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout, Bidirectional\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('result.csv')\n",
        "print(df['rating'].value_counts())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qQm6LnKeYTjJ",
        "outputId": "2125c689-2cbd-4673-f2f0-e50b06a43e3d"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "rating\n",
            "5.0    34180\n",
            "4.0     7616\n",
            "3.0     3404\n",
            "1.0     2097\n",
            "2.0     1095\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "TAHAP EKSTRAKSI FITUR DAN PELABELAN DATA"
      ],
      "metadata": {
        "id": "m7hPgZ_xqaV8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def clean_comment(teks):\n",
        "    if pd.isna(teks):\n",
        "        return \"\"\n",
        "\n",
        "    teks = str(teks).lower()\n",
        "\n",
        "    # emoji\n",
        "    emoji_pattern = re.compile(\"[\"\n",
        "        u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
        "        u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
        "        u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
        "        u\"\\U0001F1E0-\\U0001F1FF\"  # flags\n",
        "        u\"\\U00002702-\\U000027B0\"\n",
        "        u\"\\U000024C2-\\U0001F251\"\n",
        "        \"]+\", flags=re.UNICODE)\n",
        "    teks = emoji_pattern.sub(r'', teks)\n",
        "\n",
        "    # URL\n",
        "    teks = re.sub(r'http\\S+|www\\S+|https\\S+', '', teks)\n",
        "\n",
        "    # mention dan hashtag\n",
        "    teks = re.sub(r'@\\w+|#\\w+', '', teks)\n",
        "\n",
        "    # karakter khusus\n",
        "    teks = re.sub(r'[^a-z\\s]', ' ', teks)\n",
        "\n",
        "    # spasi berlebih\n",
        "    teks = re.sub(r'\\s+', ' ', teks).strip()\n",
        "\n",
        "    return teks\n",
        "\n",
        "df['comment_clean'] = df['comment'].apply(clean_comment)\n",
        "\n",
        "# empty comment\n",
        "df = df[df['comment_clean'].str.len() > 0]\n",
        "\n",
        "# duplikat\n",
        "print(f\"Duplikat ditemukan: {df.duplicated(subset=['comment_clean']).sum()}\")\n",
        "df = df.drop_duplicates(subset=['comment_clean'], keep='first')\n",
        "print(f\"Data setelah hapus duplikat: {df.shape}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2GHI26WJYU1Y",
        "outputId": "8d60687c-e407-4be9-a6da-d029bc93c027"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Duplikat ditemukan: 2746\n",
            "Data setelah hapus duplikat: (45510, 3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def label_sentimen(rating):\n",
        "    if rating >= 4.0:\n",
        "        return 2\n",
        "    elif rating >= 3.0:\n",
        "        return 1\n",
        "    else:\n",
        "        return 0\n",
        "\n",
        "\n",
        "df['sentimen'] = df['rating'].apply(label_sentimen)\n",
        "\n",
        "print(\"Distribusi sentimen:\")\n",
        "print(df['sentimen'].value_counts())\n",
        "print(\"Persentase:\")\n",
        "print(df['sentimen'].value_counts(normalize=True) * 100)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ObdLrTikYYO4",
        "outputId": "bf4c6b79-266a-4434-99a6-4f389dae0d07"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Distribusi sentimen:\n",
            "sentimen\n",
            "2    39071\n",
            "1     3286\n",
            "0     3153\n",
            "Name: count, dtype: int64\n",
            "Persentase:\n",
            "sentimen\n",
            "2    85.851461\n",
            "1     7.220391\n",
            "0     6.928148\n",
            "Name: proportion, dtype: float64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "MAX_WORDS = 10000\n",
        "MAX_LEN = 100\n",
        "\n",
        "tokenizer = Tokenizer(num_words=MAX_WORDS, oov_token='<OOV>')\n",
        "tokenizer.fit_on_texts(df['comment_clean'])\n",
        "\n",
        "sequences = tokenizer.texts_to_sequences(df['comment_clean'])\n",
        "X = pad_sequences(sequences, maxlen=MAX_LEN, padding='post', truncating='post')\n",
        "y = df['sentimen'].values\n",
        "\n",
        "print(f\"Shape X: {X.shape}\")\n",
        "print(f\"Shape y: {y.shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RLcQuh3cYa_2",
        "outputId": "d181ae64-1913-4d09-d8dd-7f8d0986ad46"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape X: (45510, 100)\n",
            "Shape y: (45510,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **PERCOBAAN 1**\n",
        "\n",
        "Ekstraksi Fitur : Word embedding\n",
        "\n",
        "Model : LSTM\n",
        "\n",
        "Train/val/test : 72/8/20"
      ],
      "metadata": {
        "id": "B0JQXG3w5upg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42, stratify=y\n",
        ")\n",
        "\n",
        "X_train, X_val, y_train, y_val = train_test_split(\n",
        "    X_train, y_train, test_size=0.1, random_state=42, stratify=y_train\n",
        ")\n",
        "\n",
        "print(f\"Train: {X_train.shape}, Val: {X_val.shape}, Test: {X_test.shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9t2YhWqrYed-",
        "outputId": "9bd335a6-798a-4bca-93fe-57b2fcc1a339"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train: (32767, 100), Val: (3641, 100), Test: (9102, 100)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Karena dataset tidak imbang tambahakan weight\n",
        "class_weights_array = compute_class_weight(\n",
        "    class_weight='balanced',\n",
        "    classes=np.unique(y_train),\n",
        "    y=y_train\n",
        ")\n",
        "\n",
        "class_weights = {i: weight for i, weight in enumerate(class_weights_array)}\n",
        "print(f\"Class weights: {class_weights}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YHiv6JGhYg0T",
        "outputId": "79dcb444-1ba8-47d6-80ec-94bf894dc7c8"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Class weights: {0: np.float64(4.811600587371513), 1: np.float64(4.616370808678501), 2: np.float64(0.3882667993790954)}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "TAHAP PELATIHAN MODEL"
      ],
      "metadata": {
        "id": "aCkj6ktt4uXY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_lstm = Sequential([\n",
        "    Embedding(input_dim=MAX_WORDS, output_dim=128, input_length=MAX_LEN),\n",
        "    Bidirectional(LSTM(64, return_sequences=True)),\n",
        "    Dropout(0.5),\n",
        "    Bidirectional(LSTM(32)),\n",
        "    Dropout(0.5),\n",
        "    Dense(64, activation='relu'),\n",
        "    Dropout(0.3),\n",
        "    Dense(3, activation='softmax')  #  negatif, netral, positif\n",
        "])\n",
        "\n",
        "model_lstm.compile(\n",
        "    optimizer='adam',\n",
        "    loss='sparse_categorical_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "model_lstm.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 450
        },
        "id": "B7EKS7krYkTw",
        "outputId": "4d9d283d-ed97-49ba-8ae1-dc792c8c8a30"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/core/embedding.py:97: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ embedding (\u001b[38;5;33mEmbedding\u001b[0m)           │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ bidirectional (\u001b[38;5;33mBidirectional\u001b[0m)   │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ ?                      │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ bidirectional_1 (\u001b[38;5;33mBidirectional\u001b[0m) │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)             │ ?                      │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_2 (\u001b[38;5;33mDropout\u001b[0m)             │ ?                      │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ embedding (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)           │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ bidirectional (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)   │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ ?                      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ bidirectional_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>) │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ ?                      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ ?                      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "early_stop = EarlyStopping(\n",
        "    monitor='val_loss',\n",
        "    patience=5,\n",
        "    restore_best_weights=True,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "reduce_lr = ReduceLROnPlateau(\n",
        "    monitor='val_loss',\n",
        "    factor=0.5,\n",
        "    patience=3,\n",
        "    min_lr=0.00001,\n",
        "    verbose=1\n",
        ")"
      ],
      "metadata": {
        "id": "WsgKZf9mYktw"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = model_lstm.fit(\n",
        "    X_train, y_train,\n",
        "    validation_data=(X_val, y_val),\n",
        "    epochs=30,\n",
        "    batch_size=32,\n",
        "    class_weight=class_weights,\n",
        "    callbacks=[early_stop, reduce_lr],\n",
        "    verbose=1\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aCd3ja_rYqIK",
        "outputId": "f498f669-fdd8-4ea4-e05b-6839dd4ce8f6"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "\u001b[1m1024/1024\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 21ms/step - accuracy: 0.6520 - loss: 0.8838 - val_accuracy: 0.8624 - val_loss: 0.4684 - learning_rate: 0.0010\n",
            "Epoch 2/30\n",
            "\u001b[1m1024/1024\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 20ms/step - accuracy: 0.8422 - loss: 0.6030 - val_accuracy: 0.8099 - val_loss: 0.5427 - learning_rate: 0.0010\n",
            "Epoch 3/30\n",
            "\u001b[1m1024/1024\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 21ms/step - accuracy: 0.8746 - loss: 0.4754 - val_accuracy: 0.8610 - val_loss: 0.4422 - learning_rate: 0.0010\n",
            "Epoch 4/30\n",
            "\u001b[1m1024/1024\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 21ms/step - accuracy: 0.8895 - loss: 0.4095 - val_accuracy: 0.8121 - val_loss: 0.5559 - learning_rate: 0.0010\n",
            "Epoch 5/30\n",
            "\u001b[1m1024/1024\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 20ms/step - accuracy: 0.9045 - loss: 0.3361 - val_accuracy: 0.8168 - val_loss: 0.5557 - learning_rate: 0.0010\n",
            "Epoch 6/30\n",
            "\u001b[1m1022/1024\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9141 - loss: 0.2919\n",
            "Epoch 6: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
            "\u001b[1m1024/1024\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 21ms/step - accuracy: 0.9141 - loss: 0.2920 - val_accuracy: 0.8580 - val_loss: 0.5182 - learning_rate: 0.0010\n",
            "Epoch 7/30\n",
            "\u001b[1m1024/1024\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 21ms/step - accuracy: 0.9220 - loss: 0.2504 - val_accuracy: 0.8476 - val_loss: 0.6077 - learning_rate: 5.0000e-04\n",
            "Epoch 8/30\n",
            "\u001b[1m1024/1024\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 21ms/step - accuracy: 0.9276 - loss: 0.2082 - val_accuracy: 0.8588 - val_loss: 0.5953 - learning_rate: 5.0000e-04\n",
            "Epoch 8: early stopping\n",
            "Restoring model weights from the end of the best epoch: 3.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "TAHAP EVALUASI"
      ],
      "metadata": {
        "id": "f0s0-iYPIb6V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# evaluasi pada test set\n",
        "test_loss, test_acc = model_lstm.evaluate(X_test, y_test, verbose=0)\n",
        "print(f\"Test Accuracy: {test_acc:.4f}\")\n",
        "print(f\"Test Loss: {test_loss:.4f}\")\n",
        "\n",
        "y_pred = model_lstm.predict(X_test)\n",
        "y_pred_classes = np.argmax(y_pred, axis=1)\n",
        "\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report(\n",
        "    y_test,\n",
        "    y_pred_classes,\n",
        "    target_names=['Negatif', 'Netral', 'Positif']\n",
        "))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t-eI4v2AYsJY",
        "outputId": "5b7af9bc-c408-422b-a5d6-b496ef45f1d4"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Accuracy: 0.8688\n",
            "Test Loss: 0.4311\n",
            "\u001b[1m285/285\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     Negatif       0.64      0.72      0.68       631\n",
            "      Netral       0.30      0.45      0.36       657\n",
            "     Positif       0.97      0.92      0.94      7814\n",
            "\n",
            "    accuracy                           0.87      9102\n",
            "   macro avg       0.63      0.70      0.66      9102\n",
            "weighted avg       0.90      0.87      0.88      9102\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def prediksi_sentimen(teks):\n",
        "    cleaned_comment = clean_comment(teks)\n",
        "    seq = tokenizer.texts_to_sequences([cleaned_comment])\n",
        "    padded = pad_sequences(seq, maxlen=MAX_LEN, padding='post', truncating='post')\n",
        "    pred = model_lstm.predict(padded, verbose=0)\n",
        "    kelas = np.argmax(pred, axis=1)[0]\n",
        "    confidence = np.max(pred) * 100\n",
        "\n",
        "    label = ['Negatif', 'Netral', 'Positif'][kelas]\n",
        "    return label, confidence, pred[0]\n",
        "\n",
        "# test prediksi\n",
        "contoh_komentar = [\n",
        "    \"Tokonya bagus banget, pelayanan ramah, barang cepat sampai!\",\n",
        "    \"Biasa aja sih, tidak terlalu istimewa\",\n",
        "    \"Mengecewakan sekali, barang tidak sesuai dan lama banget\",\n",
        "    \"Pengiriman cepat tapi kualitas produk standar\",\n",
        "    \"Sangat puas dengan pembelian ini, recommended!\"\n",
        "]\n",
        "\n",
        "for komentar in contoh_komentar:\n",
        "    label, conf, prob = prediksi_sentimen(komentar)\n",
        "    print(f\"Komentar: {komentar}\")\n",
        "    print(f\"Prediksi: {label} ({conf:.2f}%)\")\n",
        "    print(f\"Probabilitas -> Negatif: {prob[0]:.2%}, Netral: {prob[1]:.2%}, Positif: {prob[2]:.2%}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kHBfDJvajzjS",
        "outputId": "f10d567e-2621-40e8-fcc8-24e442c7d389"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Komentar: Tokonya bagus banget, pelayanan ramah, barang cepat sampai!\n",
            "Prediksi: Positif (85.08%)\n",
            "Probabilitas -> Negatif: 0.02%, Netral: 14.90%, Positif: 85.08%\n",
            "Komentar: Biasa aja sih, tidak terlalu istimewa\n",
            "Prediksi: Netral (54.15%)\n",
            "Probabilitas -> Negatif: 44.49%, Netral: 54.15%, Positif: 1.36%\n",
            "Komentar: Mengecewakan sekali, barang tidak sesuai dan lama banget\n",
            "Prediksi: Negatif (98.32%)\n",
            "Probabilitas -> Negatif: 98.32%, Netral: 1.66%, Positif: 0.02%\n",
            "Komentar: Pengiriman cepat tapi kualitas produk standar\n",
            "Prediksi: Netral (88.63%)\n",
            "Probabilitas -> Negatif: 8.09%, Netral: 88.63%, Positif: 3.28%\n",
            "Komentar: Sangat puas dengan pembelian ini, recommended!\n",
            "Prediksi: Positif (96.79%)\n",
            "Probabilitas -> Negatif: 0.00%, Netral: 3.21%, Positif: 96.79%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "# **PERCOBAAN 2**\n",
        "\n",
        "Ekstraksi fitur : TF-IDF\n",
        "\n",
        "Model : SVM\n",
        "\n",
        "train/val/test : 72/8/20"
      ],
      "metadata": {
        "id": "gEv8QsFCj0D9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.pipeline import Pipeline\n",
        "import pickle\n",
        "from collections import Counter\n"
      ],
      "metadata": {
        "id": "CzQznaEvmcW-"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tfidf = TfidfVectorizer(\n",
        "    max_features=5000,\n",
        "    ngram_range=(1, 3),  # unigram bigram trigram\n",
        "    min_df=2,  # minimal muncul di 2 dokumen\n",
        "    max_df=0.8,  # maksimal muncul di 80% dokumen\n",
        "    sublinear_tf=True  # scaling frekuensi\n",
        ")"
      ],
      "metadata": {
        "id": "BGz-JLKEkD0K"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = df['comment_clean'].values\n",
        "y = df['sentimen'].values\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42, stratify=y\n",
        ")\n",
        "\n",
        "X_train, X_val, y_train, y_val = train_test_split(\n",
        "    X_train, y_train, test_size=0.1, random_state=42, stratify=y_train\n",
        ")\n",
        "\n",
        "# simpan untuk simpulan\n",
        "y_test_svm = y_test\n",
        "\n",
        "print(f\"Train: {len(X_train)}, Val: {len(X_val)}, Test: {len(X_test)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nUE4obqttSyy",
        "outputId": "bb4618c4-e504-46df-9b24-a5f2c82f7063"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train: 32767, Val: 3641, Test: 9102\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_tfidf = tfidf.fit_transform(X_train)\n",
        "X_val_tfidf = tfidf.transform(X_val)\n",
        "X_test_tfidf = tfidf.transform(X_test)\n",
        "\n",
        "print(f\"Shape X_train_tfidf: {X_train_tfidf.shape}\")\n",
        "print(f\"Shape X_val_tfidf: {X_val_tfidf.shape}\")\n",
        "print(f\"Shape X_test_tfidf: {X_test_tfidf.shape}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-tYKog8clnVw",
        "outputId": "152e6c5c-581c-4eb7-9bbd-d265f2f15fb2"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape X_train_tfidf: (32767, 5000)\n",
            "Shape X_val_tfidf: (3641, 5000)\n",
            "Shape X_test_tfidf: (9102, 5000)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "svm_model = SVC(\n",
        "    kernel='rbf',\n",
        "    C=10,\n",
        "    gamma='scale',\n",
        "    class_weight=class_weights,\n",
        "    random_state=42,\n",
        "    probability=True,\n",
        "    verbose=True\n",
        ")\n",
        "\n",
        "print(\"training...\")\n",
        "svm_model.fit(X_train_tfidf, y_train)\n",
        "print(\"Training selesai!\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SSSkyK2Jlr32",
        "outputId": "f8a11690-2eec-4cdd-b7b0-b127e7bd8eda"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training...\n",
            "[LibSVM]Training selesai!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred_svm = svm_model.predict(X_test_tfidf)\n",
        "accuracy = accuracy_score(y_test, y_pred_svm)\n",
        "print(\"Accuracy:\", accuracy)\n",
        "\n",
        "print(classification_report(y_test, y_pred_svm))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "STbtMgT_tfTk",
        "outputId": "fe6ea4b3-8188-41d2-c3eb-5a9ab7a7179d"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.9033179520984399\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.69      0.67      0.68       631\n",
            "           1       0.41      0.20      0.26       657\n",
            "           2       0.94      0.98      0.96      7814\n",
            "\n",
            "    accuracy                           0.90      9102\n",
            "   macro avg       0.68      0.62      0.64      9102\n",
            "weighted avg       0.88      0.90      0.89      9102\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def prediksi_sentimen(teks):\n",
        "    teks_bersih = clean_comment(teks)\n",
        "    teks_tfidf = tfidf.transform([teks_bersih])\n",
        "    pred = svm_model.predict(teks_tfidf)[0]\n",
        "    prob = svm_model.predict_proba(teks_tfidf)[0]\n",
        "    confidence = max(prob) * 100\n",
        "\n",
        "    label = ['Negatif', 'Netral', 'Positif'][pred]\n",
        "    return label, confidence, prob\n",
        "\n",
        "contoh_komentar = [\n",
        "    \"Tokonya bagus banget, pelayanan ramah, barang cepat sampai!\",\n",
        "    \"Biasa aja sih, tidak terlalu istimewa\",\n",
        "    \"Mengecewakan sekali, barang tidak sesuai dan lama banget\",\n",
        "    \"Pengiriman cepat tapi kualitas produk standar\",\n",
        "    \"Sangat puas dengan pembelian ini, recommended!\"\n",
        "]\n",
        "\n",
        "for komentar in contoh_komentar:\n",
        "    label, conf, prob = prediksi_sentimen(komentar)\n",
        "    print(f\"Komentar: {komentar}\")\n",
        "    print(f\"Prediksi: {label} ({conf:.2f}%)\")\n",
        "    print(f\"Probabilitas -> Negatif: {prob[0]:.2%}, Netral: {prob[1]:.2%}, Positif: {prob[2]:.2%}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZWWdyyO_l4fn",
        "outputId": "b3cce90e-22e6-4a78-823e-3641686323b1"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Komentar: Tokonya bagus banget, pelayanan ramah, barang cepat sampai!\n",
            "Prediksi: Positif (98.28%)\n",
            "Probabilitas -> Negatif: 0.05%, Netral: 1.67%, Positif: 98.28%\n",
            "Komentar: Biasa aja sih, tidak terlalu istimewa\n",
            "Prediksi: Netral (66.77%)\n",
            "Probabilitas -> Negatif: 14.88%, Netral: 66.77%, Positif: 18.36%\n",
            "Komentar: Mengecewakan sekali, barang tidak sesuai dan lama banget\n",
            "Prediksi: Negatif (96.84%)\n",
            "Probabilitas -> Negatif: 96.84%, Netral: 2.51%, Positif: 0.65%\n",
            "Komentar: Pengiriman cepat tapi kualitas produk standar\n",
            "Prediksi: Positif (70.32%)\n",
            "Probabilitas -> Negatif: 3.01%, Netral: 26.67%, Positif: 70.32%\n",
            "Komentar: Sangat puas dengan pembelian ini, recommended!\n",
            "Prediksi: Positif (98.41%)\n",
            "Probabilitas -> Negatif: 0.26%, Netral: 1.33%, Positif: 98.41%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **PERCOBAAN 3**\n",
        "Ekstraksi fitur : Word Embedding\n",
        "\n",
        "Model : GRU\n",
        "\n",
        "train/val/test : 70/15/15"
      ],
      "metadata": {
        "id": "JiJDs4wdj_V5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.layers import SimpleRNN, GRU\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "from tensorflow.keras.optimizers import Adam"
      ],
      "metadata": {
        "id": "0zVUM4Ypj-7W"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "MAX_WORDS = 10000\n",
        "MAX_LEN = 100\n",
        "EMBEDDING_DIM = 128\n",
        "\n",
        "tokenizer = Tokenizer(num_words=MAX_WORDS, oov_token='<OOV>')\n",
        "tokenizer.fit_on_texts(df['comment_clean'])\n",
        "\n",
        "sequences = tokenizer.texts_to_sequences(df['comment_clean'])\n",
        "X = pad_sequences(sequences, maxlen=MAX_LEN, padding='post', truncating='post')\n",
        "y = df['sentimen'].values\n",
        "\n",
        "print(f\"Vocabulary size: {len(tokenizer.word_index)}\")\n",
        "print(f\"Shape X: {X.shape}\")\n",
        "print(f\"Shape y: {y.shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VLZe44gr0waN",
        "outputId": "8f11341e-a50c-473d-e199-4d034d7411a2"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vocabulary size: 20559\n",
            "Shape X: (45510, 100)\n",
            "Shape y: (45510,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y,\n",
        "    test_size=0.15,\n",
        "    random_state=42,\n",
        "    stratify=y\n",
        ")\n",
        "\n",
        "X_train, X_val, y_train, y_val = train_test_split(\n",
        "    X_train, y_train,\n",
        "    test_size=0.176,\n",
        "    random_state=42,\n",
        "    stratify=y_train\n",
        ")\n",
        "\n",
        "print(f\"Train: {X_train.shape}, Val: {X_val.shape}, Test: {X_test.shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v8zCbfDXzu_Q",
        "outputId": "9752e697-a857-4d42-f248-f40a5e75ca25"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train: (31874,), Val: (6809,), Test: (6827,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_gru = Sequential([\n",
        "  Embedding(input_dim=MAX_WORDS, output_dim=EMBEDDING_DIM, input_length=MAX_LEN),\n",
        "  Bidirectional(GRU(128, return_sequences=True)),\n",
        "  Dropout(0.5),\n",
        "  Bidirectional(GRU(64)),\n",
        "  Dropout(0.5),\n",
        "  Dense(64, activation='relu'),\n",
        "  Dropout(0.3),\n",
        "  Dense(3, activation='softmax')\n",
        "])\n",
        "\n",
        "model_gru.compile(\n",
        "    optimizer=Adam(learning_rate=0.001),\n",
        "    loss='sparse_categorical_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "model_gru.summary()\n",
        "\n",
        "early_stop = EarlyStopping(\n",
        "    monitor='val_loss',\n",
        "    patience=5,\n",
        "    restore_best_weights=True,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "reduce_lr = ReduceLROnPlateau(\n",
        "    monitor='val_loss',\n",
        "    factor=0.5,\n",
        "    patience=3,\n",
        "    min_lr=0.00001,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "checkpoint = ModelCheckpoint(\n",
        "    'best_rnn_model.h5',\n",
        "    monitor='val_accuracy',\n",
        "    save_best_only=True,\n",
        "    verbose=1\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 450
        },
        "id": "sWMrU6Swz0jz",
        "outputId": "1fdf3686-b706-426c-9d9e-f6ac1e70c0a3"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/core/embedding.py:97: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_1\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ embedding_1 (\u001b[38;5;33mEmbedding\u001b[0m)         │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ bidirectional_2 (\u001b[38;5;33mBidirectional\u001b[0m) │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_3 (\u001b[38;5;33mDropout\u001b[0m)             │ ?                      │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ bidirectional_3 (\u001b[38;5;33mBidirectional\u001b[0m) │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_4 (\u001b[38;5;33mDropout\u001b[0m)             │ ?                      │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_5 (\u001b[38;5;33mDropout\u001b[0m)             │ ?                      │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                 │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ embedding_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ bidirectional_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>) │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ ?                      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ bidirectional_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>) │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ ?                      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ ?                      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "history = model_gru.fit(\n",
        "    X_train, y_train,\n",
        "    validation_data=(X_val, y_val),\n",
        "    epochs=30,\n",
        "    batch_size=32,\n",
        "    class_weight=class_weights,\n",
        "    callbacks=[early_stop, reduce_lr, checkpoint],\n",
        "    verbose=1\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bR-KTQPfz3Of",
        "outputId": "8cb0cbf5-0410-470d-f09b-4926055720cf"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "\u001b[1m995/997\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.7333 - loss: 0.8477\n",
            "Epoch 1: val_accuracy improved from -inf to 0.65311, saving model to best_rnn_model.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m997/997\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 22ms/step - accuracy: 0.7335 - loss: 0.8475 - val_accuracy: 0.6531 - val_loss: 0.7420 - learning_rate: 0.0010\n",
            "Epoch 2/30\n",
            "\u001b[1m997/997\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.8400 - loss: 0.5887\n",
            "Epoch 2: val_accuracy improved from 0.65311 to 0.86591, saving model to best_rnn_model.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m997/997\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 22ms/step - accuracy: 0.8400 - loss: 0.5887 - val_accuracy: 0.8659 - val_loss: 0.4113 - learning_rate: 0.0010\n",
            "Epoch 3/30\n",
            "\u001b[1m997/997\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.8738 - loss: 0.4709\n",
            "Epoch 3: val_accuracy did not improve from 0.86591\n",
            "\u001b[1m997/997\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 22ms/step - accuracy: 0.8738 - loss: 0.4709 - val_accuracy: 0.8611 - val_loss: 0.4258 - learning_rate: 0.0010\n",
            "Epoch 4/30\n",
            "\u001b[1m996/997\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.8904 - loss: 0.4061\n",
            "Epoch 4: val_accuracy improved from 0.86591 to 0.86665, saving model to best_rnn_model.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m997/997\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 21ms/step - accuracy: 0.8903 - loss: 0.4061 - val_accuracy: 0.8666 - val_loss: 0.4456 - learning_rate: 0.0010\n",
            "Epoch 5/30\n",
            "\u001b[1m995/997\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9021 - loss: 0.3210\n",
            "Epoch 5: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
            "\n",
            "Epoch 5: val_accuracy did not improve from 0.86665\n",
            "\u001b[1m997/997\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 21ms/step - accuracy: 0.9021 - loss: 0.3211 - val_accuracy: 0.8431 - val_loss: 0.5238 - learning_rate: 0.0010\n",
            "Epoch 6/30\n",
            "\u001b[1m995/997\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9243 - loss: 0.2460\n",
            "Epoch 6: val_accuracy did not improve from 0.86665\n",
            "\u001b[1m997/997\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 22ms/step - accuracy: 0.9243 - loss: 0.2460 - val_accuracy: 0.8458 - val_loss: 0.5610 - learning_rate: 5.0000e-04\n",
            "Epoch 7/30\n",
            "\u001b[1m995/997\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9268 - loss: 0.2093\n",
            "Epoch 7: val_accuracy did not improve from 0.86665\n",
            "\u001b[1m997/997\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 22ms/step - accuracy: 0.9268 - loss: 0.2093 - val_accuracy: 0.8572 - val_loss: 0.5619 - learning_rate: 5.0000e-04\n",
            "Epoch 7: early stopping\n",
            "Restoring model weights from the end of the best epoch: 2.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_loss, test_acc = model_gru.evaluate(X_test, y_test, verbose=0)\n",
        "print(f\"Test Accuracy: {test_acc:.4f}\")\n",
        "print(f\"Test Loss: {test_loss:.4f}\")\n",
        "\n",
        "y_pred = model_gru.predict(X_test, verbose=0)\n",
        "y_pred_classes = np.argmax(y_pred, axis=1)\n",
        "\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report(\n",
        "    y_test,\n",
        "    y_pred_classes,\n",
        "    target_names=['Negatif', 'Netral', 'Positif'],\n",
        "    digits=4\n",
        "))\n",
        "\n",
        "for i, label in enumerate(['Negatif', 'Netral', 'Positif']):\n",
        "    mask = y_test == i\n",
        "    if mask.sum() > 0:\n",
        "        class_acc = (y_pred_classes[mask] == i).sum() / mask.sum()\n",
        "        print(f\"Akurasi {label}: {class_acc:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oCjYTHKLz7mD",
        "outputId": "a1c3d591-aa08-42c6-cbc7-721bae0d93fa"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Accuracy: 0.8686\n",
            "Test Loss: 0.3920\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     Negatif     0.6275    0.6660    0.6462       473\n",
            "      Netral     0.3168    0.5172    0.3929       493\n",
            "     Positif     0.9710    0.9145    0.9419      5861\n",
            "\n",
            "    accuracy                         0.8686      6827\n",
            "   macro avg     0.6384    0.6992    0.6603      6827\n",
            "weighted avg     0.9000    0.8686    0.8818      6827\n",
            "\n",
            "Akurasi Negatif: 0.6660\n",
            "Akurasi Netral: 0.5172\n",
            "Akurasi Positif: 0.9145\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "embedding_layer = model_gru.layers[0]\n",
        "embeddings = embedding_layer.get_weights()[0]\n",
        "\n",
        "print(f\"Shape embedding matrix: {embeddings.shape}\")\n",
        "print(f\"Jumlah kata dalam vocabulary: {embeddings.shape[0]}\")\n",
        "print(f\"Dimensi embedding per kata: {embeddings.shape[1]}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0dSJNP-y1P66",
        "outputId": "5d0f4e3c-3d80-4b6c-d965-588a39938fed"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape embedding matrix: (10000, 128)\n",
            "Jumlah kata dalam vocabulary: 10000\n",
            "Dimensi embedding per kata: 128\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def prediksi_sentimen(teks):\n",
        "    teks_bersih = clean_comment(teks)\n",
        "    seq = tokenizer.texts_to_sequences([teks_bersih])\n",
        "    padded = pad_sequences(seq, maxlen=MAX_LEN, padding='post', truncating='post')\n",
        "    pred = model_gru.predict(padded, verbose=0)\n",
        "    kelas = np.argmax(pred, axis=1)[0]\n",
        "    confidence = np.max(pred) * 100\n",
        "    prob = pred[0]\n",
        "\n",
        "    label = ['Negatif', 'Netral', 'Positif'][kelas]\n",
        "    return label, confidence, prob\n",
        "\n",
        "contoh_komentar = [\n",
        "    \"Tokonya bagus banget, pelayanan ramah, barang cepat sampai!\",\n",
        "    \"Biasa aja sih, tidak terlalu istimewa\",\n",
        "    \"Mengecewakan sekali, barang tidak sesuai dan lama banget\",\n",
        "    \"Pengiriman cepat tapi kualitas produk standar\",\n",
        "    \"Sangat puas dengan pembelian ini, recommended!\",\n",
        "    \"Buruk, tidak akan beli lagi di sini\"\n",
        "]\n",
        "\n",
        "for komentar in contoh_komentar:\n",
        "    label, conf, prob = prediksi_sentimen(komentar)\n",
        "    print(f\"Komentar: {komentar}\")\n",
        "    print(f\"Prediksi: {label} ({conf:.2f}%)\")\n",
        "    print(f\"Probabilitas -> Negatif: {prob[0]:.2%}, Netral: {prob[1]:.2%}, Positif: {prob[2]:.2%}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lVF59VUC1TI2",
        "outputId": "e5d7fca3-5ee4-4666-e968-3e8f7c2aa7ac"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Komentar: Tokonya bagus banget, pelayanan ramah, barang cepat sampai!\n",
            "Prediksi: Positif (94.60%)\n",
            "Probabilitas -> Negatif: 0.03%, Netral: 5.36%, Positif: 94.60%\n",
            "Komentar: Biasa aja sih, tidak terlalu istimewa\n",
            "Prediksi: Netral (64.67%)\n",
            "Probabilitas -> Negatif: 33.29%, Netral: 64.67%, Positif: 2.05%\n",
            "Komentar: Mengecewakan sekali, barang tidak sesuai dan lama banget\n",
            "Prediksi: Negatif (94.09%)\n",
            "Probabilitas -> Negatif: 94.09%, Netral: 5.89%, Positif: 0.02%\n",
            "Komentar: Pengiriman cepat tapi kualitas produk standar\n",
            "Prediksi: Netral (58.92%)\n",
            "Probabilitas -> Negatif: 11.55%, Netral: 58.92%, Positif: 29.52%\n",
            "Komentar: Sangat puas dengan pembelian ini, recommended!\n",
            "Prediksi: Positif (96.50%)\n",
            "Probabilitas -> Negatif: 0.01%, Netral: 3.49%, Positif: 96.50%\n",
            "Komentar: Buruk, tidak akan beli lagi di sini\n",
            "Prediksi: Negatif (84.93%)\n",
            "Probabilitas -> Negatif: 84.93%, Netral: 14.96%, Positif: 0.11%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **INTERPRETASI DAN KESIMPULAN**\n"
      ],
      "metadata": {
        "id": "4ca17UYq2-ch"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## LSTM\n",
        "Accuracy : 0.8688\n",
        "\n",
        "## SVM\n",
        "Accuracy : 0.9033\n",
        "\n",
        "## GRU\n",
        "Accuracy : 0.8686\n",
        "\n",
        "**### Penjelasan**\n",
        "\n",
        "Perbedaan performa antar percobaan terutama dipengaruhi oleh metode ekstraksi fitur, jenis model, serta kondisi data yang tidak seimbang. Pada Percobaan 2 (TF-IDF + SVM) mempunyai akurasi yang tertinggi karena SVM sangat efektif memisahkan kelas dominan menggunakan fitur kata eksplisit, sehingga model cenderung memprediksi kelas positif yang jumlahnya sangat besar. Namun, pendekatan ini mengorbankan kemampuan mengenali kelas minoritas, terutama kelas netral yang bisa dilihat dari nilai recall netral yang sangat rendah.\n",
        "\n",
        "Pada Percobaan 1 (Word Embedding + LSTM), model mampu menangkap konteks dan urutan kata sehingga lebih sensitif terhadap sentimen negatif, tetapi kompleksitas LSTM membuatnya kurang optimal pada data yang imbalanced dan menyebabkan kesulitan dalam membedakan kelas netral yang secara linguistik ambigu. Sementara itu, Percobaan 3 (Word Embedding + GRU) menunjukkan performa yang lebih seimbang karena arsitektur GRU yang lebih sederhana dan stabil mampu mengurangi overfitting terhadap kelas mayoritas. Hal ini terlihat dari nilai loss yang lebih rendah serta recall kelas netral yang paling tinggi, sehingga meskipun akurasi total tidak setinggi SVM, GRU memberikan representasi performa yang lebih adil untuk seluruh kelas sentimen."
      ],
      "metadata": {
        "id": "MAwHVHE-MX4M"
      }
    }
  ]
}